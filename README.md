Hi, I'm Deepak! 

üë®‚Äçüíª With around 8 years of experience as a Data Engineer, I specialize in designing and managing data-intensive applications using the Hadoop ecosystem, Big Data analytical tools, and Cloud Data Engineering. My expertise lies in building and maintaining distributed data systems on AWS and Azure, utilizing services such as AWS S3, EMR, EC2, Lambda functions, Redshift, Athena, and AWS Glue. I have a proven track record of deploying and managing AWS RDS instances for seamless data processing and storage.

üîó My technical proficiency extends to integrating Apache NiFi with Azure services like Azure Data Lake, Azure Blob Storage, and Azure SQL Database for secure data transfer. I am adept at automating and scheduling data workflows using Azure Data Bricks and Azure Data Factory, and designing complex data integration workflows with Informatica Power Centre.

üíª I possess strong programming skills in SQL, Scala, and Python, with a deep understanding of Python libraries such as Pandas, NumPy, and SciPy for data cleaning and analysis. My experience encompasses working with various relational databases, including MS SQL Server and Oracle, and I have expertise in schema design and data modeling for NoSQL and PostgreSQL databases.

‚öôÔ∏è My knowledge of Hadoop architecture, Kafka Streams, and KSQL enables me to perform real-time data processing and analytics efficiently. I excel at integrating Kafka with big data processing frameworks like Apache Hadoop, Apache Spark, and Apache Flink using Scala. Additionally, I am skilled in workflow automation with Airflow, data visualization with Tableau and Power BI, and container orchestration with Kubernetes. I also utilize GitHub Actions for CI/CD pipelines, ensuring efficient testing and deployment processes.


<!---
Deepak-6737/Deepak-6737 is a ‚ú® special ‚ú® repository because its `README.md` (this file) appears on your GitHub profile.
You can click the Preview link to take a look at your changes.
--->
